{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9VFWEHTMiN",
        "colab_type": "text"
      },
      "source": [
        "Практическое задание к уроку 4 часть 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajFZRDlR7MCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "46761ada-6586-44e7-de15-55ca70a7e50f"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 1\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(64, (3,3), padding='same',\n",
        "               input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(78, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(78, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(90, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "#if not os.path.isdir(save_dir):\n",
        "#    os.makedirs(save_dir)\n",
        "#model_path = os.path.join(save_dir, model_name)\n",
        "#model.save(model_path)\n",
        "#print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "Использование data augmentation в реальном времени\n",
            "1563/1563 [==============================] - 2593s 2s/step - loss: 1.8980 - accuracy: 0.2897 - val_loss: 1.5346 - val_accuracy: 0.4295\n",
            "313/313 [==============================] - 125s 399ms/step - loss: 1.5346 - accuracy: 0.4295\n",
            "Test loss: 1.534576177597046\n",
            "Test accuracy: 0.429500013589859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIfP3xJ0V1fx",
        "colab_type": "text"
      },
      "source": [
        "1 эпоха\n",
        "Test accuracy: 0.4284999966621399\n",
        "5 эпох  Test accuracy: 0.5809000134468079\n",
        "\n",
        "добавление слоев точность как увеличивалась так и понижалась, что связано с недообученностью и конфигурацией модели (фильтров)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C3OvTBUTt0B",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq31O7w0UQY3",
        "colab_type": "text"
      },
      "source": [
        "Вывод: \n",
        "- основное влияние оказывает количество эпох обучения при фиксированной конфигурации.\n",
        "- архитектура сети,количество слоев. количество фильтров (хорошо влияет на производительность, толщина слоя) точность как увеличивалась так и понижалась, что связано с недообученностью и конфигурацией модели. т.е простое добавление слоев не даст существенного прироста (повысит время обработки), важно оптимизация модели (от затраченных ресурсов на обучение).\n",
        "- варьирование размером bath, также позваляет повысить точность или скорость обработки. т.к Keras производит изменения параметров после обучения по 1 bath. при слишком малом размере будет скорость обработки. при слишком большом недообученность.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shU1yexvDC06",
        "colab_type": "text"
      },
      "source": [
        "Практическое задание к уроку 4 часть 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKGElLlHDMZJ",
        "colab_type": "text"
      },
      "source": [
        "1. dataset mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1ejrLFRmWhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "13286c72-3320-40e3-aea7-eeb544790e66"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,Conv1D\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "x_train=x_train.reshape(60000,28,28,1)\n",
        "x_test=x_test.reshape(10000,28,28,1)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "print('x_train shape:', x_train.shape[1:])\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(32, (3,3), padding='same',\n",
        "               input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "x_train shape: (28, 28, 1)\n",
            "Использование data augmentation в реальном времени\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 228s 122ms/step - loss: 1.1956 - accuracy: 0.5817 - val_loss: 0.3829 - val_accuracy: 0.8764\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 229s 122ms/step - loss: 0.5267 - accuracy: 0.8248 - val_loss: 0.2135 - val_accuracy: 0.9352\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 229s 122ms/step - loss: 0.3593 - accuracy: 0.8846 - val_loss: 0.1434 - val_accuracy: 0.9555\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 229s 122ms/step - loss: 0.2784 - accuracy: 0.9129 - val_loss: 0.1031 - val_accuracy: 0.9690\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 230s 123ms/step - loss: 0.2246 - accuracy: 0.9316 - val_loss: 0.0849 - val_accuracy: 0.9727\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.0849 - accuracy: 0.9727\n",
            "Test loss: 0.08491693437099457\n",
            "Test accuracy: 0.9726999998092651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAs_YjczETeu",
        "colab_type": "text"
      },
      "source": [
        "2. dataset cifar100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaT4_yOkDWcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3151607d-5003-4752-efdf-8cca79792e4a"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "batch_size = 32\n",
        "num_classes = 100\n",
        "epochs = 1\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')\n",
        "print('x_train shape:', x_train.shape[1:])\n",
        "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# конфигурирование слоев нейросети\n",
        "model = Sequential()\n",
        "\n",
        "# слои нейросети отвественные за свертку и max-pooling\n",
        "model.add(Conv2D(64, (3,3), padding='same',\n",
        "               input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(78, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(78, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(90, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# полносвязные слои нейронной сети\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# инициализация RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Не используется data augmentation')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Использование data augmentation в реальном времени')\n",
        "    # Препроцессинг и data augmentation в реальном времени:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # запуск data augmentation через fit\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # запуск data augmentation через fit_generator\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# сохранение модели и весов\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('сохранить обученную модель как %s ' % model_path)\n",
        "\n",
        "# проверка работы обученной модели\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n",
            "x_train shape: (32, 32, 3)\n",
            "Не используется data augmentation\n",
            "1563/1563 [==============================] - 2674s 2s/step - loss: 4.3968 - accuracy: 0.0274 - val_loss: 4.1230 - val_accuracy: 0.0646\n",
            "сохранить обученную модель как /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 128s 410ms/step - loss: 4.1230 - accuracy: 0.0646\n",
            "Test loss: 4.122974395751953\n",
            "Test accuracy: 0.06459999829530716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPWAQSvVWNkm",
        "colab_type": "text"
      },
      "source": [
        "Вывод:\n",
        "-Для mnist dataset: т.к изображение проедставлено в сером цвете то shape(60000,28,28) для слоя Conv2d (60000,28,28,3) (RGB), входные данные не подходят для подачи в модель для совместимости требуется. x_train=x_train.reshape(60000,28,28,1) или \n",
        "x_test=x_test.reshape(10000,28,28,1)\n",
        "Test accuracy: 0.9726999998092651\n",
        "-Для Cifar100 dataset: количество класов меняем на 100 остальное без изменений.\n",
        "для 1 эпохи обучения с добавлением слоев Test accuracy: 0.06459999829530716.\n",
        "точность можно увеличить увеличив количество эпох\n",
        "\n"
      ]
    }
  ]
}